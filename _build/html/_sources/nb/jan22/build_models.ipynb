{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "561af485-e9bd-42a7-afe6-a17c7979db85",
   "metadata": {
    "tags": []
   },
   "source": [
    "# January 21-25, 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "208e90c2-fbc9-48ab-9f66-41024f3852b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/govindas/venvs/expln-ai3.9/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:37: UserWarning: You are currently using a nightly version of TensorFlow (2.9.0-dev20220124). \n",
      "TensorFlow Addons offers no support for the nightly versions of TensorFlow. Some things might work, some other might not. \n",
      "If you encounter a bug, do not file an issue on GitHub.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from os.path import join as pjoin\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import pickle \n",
    "\n",
    "import shap\n",
    "\n",
    "# main dirs\n",
    "proj_dir = pjoin(os.environ['HOME'], 'explainable-ai')\n",
    "\n",
    "# folders\n",
    "sys.path.insert(0, proj_dir)\n",
    "from helpers.dataset_utils import *\n",
    "from helpers.base_model import *\n",
    "from helpers.model_definitions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020499ef-abb1-44f6-a539-bbda337643bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43a1d088-6eec-4df5-8cf5-e754a6ede8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "with open(pjoin(proj_dir, 'data/emoprox2', 'train_test_arrays.pkl'), 'rb') as f:\n",
    "    data_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4692eaa0-0aa3-40d0-a7c8-9080c60c6994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-26 20:49:05.405064: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-26 20:49:06.876323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14796 MB memory:  -> device: 0, name: Quadro RTX 5000, pci bus id: 0000:17:00.0, compute capability: 7.5\n",
      "2022-01-26 20:49:06.878511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14796 MB memory:  -> device: 1, name: Quadro RTX 5000, pci bus id: 0000:65:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# converting to tf tensors\n",
    "data_dict['train'] = to_tensor(data_dict['train'])\n",
    "data_dict['test'] = to_tensor(data_dict['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cec183a-da55-488f-9427-7c1e10840cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = data_dict['train'][0]\n",
    "train_y = data_dict['train'][1]\n",
    "train_mask = data_dict['train'][2]\n",
    "\n",
    "test_X = data_dict['test'][0]\n",
    "test_y = data_dict['test'][1]\n",
    "test_mask = data_dict['test'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbaa9310-308d-4425-9d2b-47fbeaa7a53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([647, 360, 85])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd049c5e-4c4a-4803-8a0e-996b36b6a38f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1fb6dd4-0c81-4438-a91b-59f27c6e8785",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Linear_Model()\n",
    "\n",
    "default_slice = lambda x, start, end : x[start : end, ...]\n",
    "\n",
    "linear_regression = base_model(task_type=\"regression\", \n",
    "                               model=model, \n",
    "                               loss_object=tf.keras.losses.MeanSquaredError(), \n",
    "                               L1_scale=0.0, \n",
    "                               L2_scale=0.0,\n",
    "                               optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), \n",
    "                               eval_metric=tfa.metrics.RSquare(),\n",
    "                               eval_metric_name=\"% var explained\",\n",
    "                               batch_size=32, \n",
    "                               slice_input=default_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40d2520-7fb3-4e6a-9879-dfcb57672444",
   "metadata": {
    "tags": []
   },
   "source": [
    "## train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5c2950a-96ba-47bf-b349-61d7acb2e5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: Train Loss: 0.155, Train % var explained: -106.072%  Val Loss: 0.096, Val % var explained: -35.013%  \n",
      "Epoch 001: Train Loss: 0.079, Train % var explained: -9.911%  Val Loss: 0.069, Val % var explained: 2.910%  \n",
      "Epoch 002: Train Loss: 0.067, Train % var explained: 5.588%  Val Loss: 0.066, Val % var explained: 7.320%  \n",
      "Epoch 003: Train Loss: 0.066, Train % var explained: 7.418%  Val Loss: 0.066, Val % var explained: 7.759%  \n",
      "Epoch 004: Train Loss: 0.066, Train % var explained: 7.492%  Val Loss: 0.066, Val % var explained: 7.755%  \n",
      "Epoch 005: Train Loss: 0.066, Train % var explained: 7.178%  Val Loss: 0.066, Val % var explained: 7.647%  \n",
      "Epoch 006: Train Loss: 0.067, Train % var explained: 6.475%  Val Loss: 0.066, Val % var explained: 7.497%  \n",
      "Epoch 007: Train Loss: 0.068, Train % var explained: 5.540%  Val Loss: 0.066, Val % var explained: 7.436%  \n",
      "Epoch 008: Train Loss: 0.068, Train % var explained: 4.887%  Val Loss: 0.066, Val % var explained: 7.221%  \n",
      "Epoch 009: Train Loss: 0.068, Train % var explained: 5.250%  Val Loss: 0.066, Val % var explained: 6.883%  \n"
     ]
    }
   ],
   "source": [
    "results = linear_regression.fit(train_X=train_X, \n",
    "                                train_Y=train_y, \n",
    "                                val_X=train_X, \n",
    "                                val_Y=train_y, \n",
    "                                num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b7116b-e36b-4a51-9962-6a0e6654e634",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Shapley values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04ae5984-e259-48c1-81ec-f1bc89124b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a set of background examples to take an expectation over\n",
    "s = train_X.shape\n",
    "X = tf.reshape(train_X, shape=(s[0]*s[1], s[2])).numpy()\n",
    "X_background = shap.utils.sample(X, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cc67030-16f7-4cbe-a396-fc35c29ecbec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc721035a4e9408080f50a535f09b3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    }
   ],
   "source": [
    "explainer = shap.KernelExplainer(model=linear_regression.model, \n",
    "                                 data=X_background)\n",
    "shap_values = explainer.shap_values(test_X[0, 0:1, :].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fb670ce-408f-4b61-b67f-7deba57a65d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 85)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_values.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
