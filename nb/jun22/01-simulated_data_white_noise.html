
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>June 4, 2022: creating simulated data: white noise &#8212; My Project [Daily Progress]</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="June 6-8, 2022: simulated data: wss noise" href="01-simulated_data_wss_noise.html" />
    <link rel="prev" title="May 30, 2022: Data samples and model" href="01-max_data_samples.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">My Project [Daily Progress]</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../intro.html">
   Welcome
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  January 2022
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../jan22/jan22.html">
   Summary
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../jan22/jan22_updates.html">
   Updates
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../jan22/date21.html">
     Jan 21, 2022
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../jan22/extract-dataset.html">
       get dataset: emoproxII
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../jan22/date30.html">
     Jan 30, 2022
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../jan22/intro_shap_values.html">
       January 30, 2022: intro to shap explanations
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  February 2022
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../feb22/feb22.html">
   Summary
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../feb22/feb22_updates.html">
   Updates
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../feb22/date1.html">
     Feb 1, 2022
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../feb22/basic_pipeline.html">
       February 1-2, 10-14, 2022: complete basic pipeline
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../feb22/date15.html">
     Feb 15, 2022
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../feb22/visualize_data.html">
       visualize the data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../feb22/linear_regression.html">
       build a simple linear model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../feb22/model_explanations.html">
       model explanations
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  March 2022
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../mar22/mar22.html">
   Summary
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../mar22/mar22_updates.html">
   Updates
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../mar22/01-ROIwise_nearmiss_segments_data_and_model.html">
     March 3-10, 2022: emoprox2 approach vs retreat segments classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../mar22/02-ROIwise_nearmiss_segments_data_and_null_models.html">
     March 16, 2022: null models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../mar22/03-ROIwise_nearmiss_segments_saliency.html">
     March 11, 14-15, 2022: saliency maps
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../mar22/04-ROIwise_nearmiss_segments_null_saliency.html">
     March 23, 2022: null saliency
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../mar22/05-ROIwise_nearmiss_segments_lesion_analysis.html">
     March 25, 28, 2022: lesion analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../mar22/06-ROIwise_analysis_emoprox2_full_dataset.html">
     March 29,30, 2022: analysis on emoprox2 full dataset
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  April 2022
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../apr22/apr22.html">
   Summary
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../apr22/apr22_updates.html">
   Updates
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../apr22/00-ROIwise_analysis_emoprox2_full_dataset_300ROIs_hemolag2.html">
     April 2, 2022: Schaefer parcellation (300), hemodynamic lag 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../apr22/00-ROIwise_analysis_emoprox2_full_dataset_300ROIs_hemolag3.html">
     April 2, 2022: Schaefer parcellation (300), hemodynamic lag 3
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../apr22/01-Schaefer2018_roi300_net7_beta_timeseries.html">
     April 4, 2022: emoprox near_miss_data proximity regressor beta time series
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../apr22/00-ROIwise_analysis_emoprox2_full_dataset_300ROIs_hemolags_comp.html">
     April 6, 2022: Schaefer parcellation (300), hemodynamic lags comparison
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../apr22/01-ROIwise_appr_retr_timeseries_plots.html">
     April 6-8, 2022: Schaefer parcellation (300), plot fMRI time series of approach and retreat segments
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../apr22/00-ROIwise_analysis_emoprox2_near_misses_300ROIs_hemolags_comp.html">
     April 11, 2022: Schaefer parcellation (300), near misses dataset, hemodynamic lags comparison
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../apr22/02-understanding_emoprox2_stimulus.html">
     April 14,15,20,21, 2022: Understanding stimulus of emoprox2 paradigm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../apr22/03-create_stimuli.html">
     April 25-30, 2022: create emoprox2 stimuli/regressors
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  May 2022
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../may22/may22.html">
   Summary
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../may22/may22_updates.html">
   Updates
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../may22/00-idea1_create_dataset_MAXROIs.html">
     May 3-4, 13-18, 2022: Idea1: don’t care labels: create dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../may22/00-idea1_model_MAXROIs.html">
     May 11-14,19, 2022: Idea1: don’t care labels: create and train a model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../may22/01-checking_temporal_masking_MAXROIs.html">
     May 19, 2022: Check temporal masking in another dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../may22/01-checking_temporal_masking_300ROIs.html">
     May 20, 2022: Check temporal masking in another dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../may22/00-idea1_model_pytorch.html">
     May 21,24,25, 2022: pytorch implementation of model: idea1
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  June 2022
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="jun22.html">
   Summary
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="jun22_updates.html">
   Updates
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="00-max_dataset.html">
     May 28, 2022: Create MAX dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="01-max_data_samples.html">
     May 30, 2022: Data samples and model
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     June 4, 2022: creating simulated data: white noise
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="01-simulated_data_wss_noise.html">
     June 6-8, 2022: simulated data: wss noise
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/nb/jun22/01-simulated_data_white_noise.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/govinda-umd/explainable-ai"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/govinda-umd/explainable-ai/issues/new?title=Issue%20on%20page%20%2Fnb/jun22/01-simulated_data_white_noise.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/govinda-umd/explainable-ai/master?urlpath=tree/docs/nb/jun22/01-simulated_data_white_noise.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data">
   data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#models">
   models
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>June 4, 2022: creating simulated data: white noise</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data">
   data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#models">
   models
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="june-4-2022-creating-simulated-data-white-noise">
<h1>June 4, 2022: creating simulated data: white noise<a class="headerlink" href="#june-4-2022-creating-simulated-data-white-noise" title="Permalink to this headline">¶</a></h1>
<p>The goal is to see how well the NN can do with data with very little noise. Is that a trivial problem to learn? Or very difficult even with just a little bit of noise.
Real data have a ton of noise.</p>
<ol class="simple">
<li><p>adding white noise to the mean time series of each condition</p></li>
<li><p>training models and checking their performances</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">os.path</span> <span class="kn">import</span> <span class="n">join</span> <span class="k">as</span> <span class="n">pjoin</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span> 
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">())</span>

<span class="kn">import</span> <span class="nn">pickle</span><span class="o">,</span> <span class="nn">time</span><span class="o">,</span> <span class="nn">random</span>
<span class="c1"># import neural_structured_learning as nsl</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">combinations</span><span class="p">,</span> <span class="n">product</span>
<span class="kn">from</span> <span class="nn">operator</span> <span class="kn">import</span> <span class="n">add</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">from</span> <span class="nn">glob</span> <span class="kn">import</span> <span class="n">glob</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>

<span class="c1"># explanation tools</span>
<span class="kn">import</span> <span class="nn">captum</span>

<span class="c1"># plotting</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">import</span> <span class="nn">matplotlib.colors</span> <span class="k">as</span> <span class="nn">mcolors</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParamsDefault</span><span class="p">[</span><span class="s1">&#39;font.family&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;sans-serif&quot;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParamsDefault</span><span class="p">[</span><span class="s1">&#39;font.sans-serif&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;Arial&quot;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">14</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;errorbar.capsize&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.5</span>

<span class="c1"># nilearn</span>
<span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">image</span>
<span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">masking</span>
<span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">plotting</span>

<span class="c1"># main dirs</span>
<span class="n">proj_dir</span> <span class="o">=</span> <span class="n">pjoin</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;HOME&#39;</span><span class="p">],</span> <span class="s1">&#39;explainable-ai&#39;</span><span class="p">)</span>
<span class="n">results_dir</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">proj_dir</span><span class="si">}</span><span class="s2">/results&quot;</span>
<span class="n">month_dir</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">proj_dir</span><span class="si">}</span><span class="s2">/nb/jun22&quot;</span>

<span class="c1"># folders</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">proj_dir</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">helpers.dataset_utils</span> <span class="k">as</span> <span class="nn">dataset_utils</span>
<span class="kn">import</span> <span class="nn">helpers.base_model</span> <span class="k">as</span> <span class="nn">base_model</span>
<span class="kn">import</span> <span class="nn">helpers.model_definitions</span> <span class="k">as</span> <span class="nn">model_definitions</span>

<span class="c1"># cuda device</span>
<span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda:1&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2"> device&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-06-07 20:00:24.060975: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Using cuda:1 device
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_training_history</span><span class="p">(</span><span class="n">history</span><span class="p">,</span> <span class="n">best_epoch</span><span class="p">):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span>
        <span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span>
        <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span>
    <span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span>
        <span class="n">left</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
        <span class="n">right</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
        <span class="n">wspace</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.5</span>
    <span class="p">)</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;tomato&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-.&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;training_loss&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;valid_loss&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;forestgreen&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;valid_loss&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;losses&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;epochs&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_acc&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;tomato&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-.&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;training_acc&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;valid_acc&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;forestgreen&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;valid_acc&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">best_epoch</span><span class="p">,</span> <span class="n">ymax</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;best_epoch&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;accuracies&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;epochs&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;valid acc. </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;valid_acc&#39;</span><span class="p">])</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">plot_confusion_matrix</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">pred_labels</span><span class="p">):</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="n">args</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="mi">3</span><span class="o">*</span><span class="n">args</span><span class="o">.</span><span class="n">num_classes</span><span class="p">))</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">cm</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">pred_labels</span><span class="p">)</span>
    <span class="n">cm</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">ConfusionMatrixDisplay</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">display_labels</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_classes</span><span class="p">))</span>
    <span class="n">cm</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">values_format</span><span class="o">=</span><span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Blues&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">opt</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">permutation</span><span class="p">):</span>
    <span class="n">epoch_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">epoch_accs</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>

        <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="n">indices</span> <span class="o">=</span> <span class="n">permutation</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>
        <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">indices</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>

        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch_x</span><span class="p">,)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span>
            <span class="n">y_pred</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">out_dim</span><span class="p">),</span> 
            <span class="n">batch_y</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="n">acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">accuracy</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">batch_y</span><span class="p">)</span>

        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">epoch_losses</span> <span class="o">+=</span> <span class="p">[</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span>
        <span class="n">epoch_accs</span> <span class="o">+=</span> <span class="p">[</span><span class="n">acc</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span>

    <span class="k">return</span>  <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">epoch_losses</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">epoch_losses</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">epoch_accs</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">epoch_accs</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">permutation</span><span class="p">):</span>
    <span class="n">epoch_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">epoch_accs</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">permutation</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>
            <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">indices</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>

            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch_x</span><span class="p">,)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span>
                <span class="n">y_pred</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">out_dim</span><span class="p">),</span> 
                <span class="n">batch_y</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="n">acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">accuracy</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">batch_y</span><span class="p">)</span>

            <span class="n">epoch_losses</span> <span class="o">+=</span> <span class="p">[</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span>
            <span class="n">epoch_accs</span> <span class="o">+=</span> <span class="p">[</span><span class="n">acc</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span>
    
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">epoch_losses</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">epoch_losses</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">epoch_accs</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">epoch_accs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="n">X_tr</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">,</span> <span class="n">X_te</span><span class="p">,</span> <span class="n">y_te</span> <span class="o">=</span> <span class="n">data</span>
    <span class="n">best_valid_loss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>

    <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_epochs</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_epochs</span><span class="p">)</span>
    <span class="n">valid_loss</span><span class="p">,</span> <span class="n">valid_acc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_epochs</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_epochs</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">train_loss</span><span class="p">[</span><span class="n">epoch</span><span class="p">],</span> <span class="n">train_acc</span><span class="p">[</span><span class="n">epoch</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_tr</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">permut_train</span><span class="p">)</span>
        <span class="n">valid_loss</span><span class="p">[</span><span class="n">epoch</span><span class="p">],</span> <span class="n">valid_acc</span><span class="p">[</span><span class="n">epoch</span><span class="p">]</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">permut_valid</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">valid_loss</span><span class="p">[</span><span class="n">epoch</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">best_valid_loss</span><span class="p">:</span>
            <span class="n">best_valid_loss</span> <span class="o">=</span> <span class="n">valid_loss</span><span class="p">[</span><span class="n">epoch</span><span class="p">]</span>
            <span class="c1"># torch.save(model.state_dict(), model_file)</span>
            <span class="n">best_model</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
            <span class="n">best_epoch</span> <span class="o">=</span> <span class="n">epoch</span>
        
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">:</span><span class="s1">02</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="p">[</span><span class="n">epoch</span><span class="p">]</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1"> | Train Acc: </span><span class="si">{</span><span class="n">train_acc</span><span class="p">[</span><span class="n">epoch</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1"> Val. Loss: </span><span class="si">{</span><span class="n">valid_loss</span><span class="p">[</span><span class="n">epoch</span><span class="p">]</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1"> |  Val. Acc: </span><span class="si">{</span><span class="n">valid_acc</span><span class="p">[</span><span class="n">epoch</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>

    <span class="n">history</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="n">train_loss</span><span class="p">,</span>
        <span class="s1">&#39;train_acc&#39;</span><span class="p">:</span> <span class="n">train_acc</span><span class="p">,</span>
        <span class="s1">&#39;valid_loss&#39;</span><span class="p">:</span> <span class="n">valid_loss</span><span class="p">,</span>
        <span class="s1">&#39;valid_acc&#39;</span><span class="p">:</span> <span class="n">valid_acc</span>
    <span class="p">}</span>

    <span class="c1"># torch.save(model.state_dict(), model_file)</span>
    <span class="c1"># with open(history_file, &#39;wb&#39;) as f:</span>
    <span class="c1">#     pickle.dump(history, f)</span>

    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">best_model</span><span class="p">,</span> <span class="n">history</span><span class="p">,</span> <span class="n">best_epoch</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_roi_time_series</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">savefig</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fig_file</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">X_conds</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">LABELS</span><span class="p">:</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">label</span>
        <span class="n">X_conds</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s2">_m&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">X_conds</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s2">_s&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">idx</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="n">roi_name_file</span> <span class="o">=</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;HOME&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">/parcellations/MAX_85_ROI_masks/ROI_names.txt&quot;</span>
    <span class="p">)</span>
    <span class="n">roi_names</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">roi_name_file</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;roi_name&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

    <span class="n">time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;safe&#39;</span><span class="p">,</span> <span class="s1">&#39;threat&#39;</span><span class="p">]</span>
    <span class="n">colors</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="s1">&#39;royalblue&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="s1">&#39;firebrick&#39;</span><span class="p">}</span>
    <span class="n">nrows</span><span class="p">,</span> <span class="n">ncols</span> <span class="o">=</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">5</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span>
        <span class="n">nrows</span><span class="o">=</span><span class="n">nrows</span><span class="p">,</span> 
        <span class="n">ncols</span><span class="o">=</span><span class="n">ncols</span><span class="p">,</span> 
        <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="o">*</span><span class="n">ncols</span><span class="p">,</span> <span class="mi">4</span><span class="o">*</span><span class="n">nrows</span><span class="p">),</span> 
        <span class="n">sharex</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
        <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
        <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span>
    <span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span>
        <span class="n">left</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
        <span class="n">right</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
        <span class="n">wspace</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.5</span>
    <span class="p">)</span>

    <span class="k">for</span> <span class="n">idx_roi</span><span class="p">,</span> <span class="n">roi_name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">roi_names</span><span class="p">):</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="n">idx_roi</span><span class="o">//</span><span class="n">ncols</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mod</span><span class="p">(</span><span class="n">idx_roi</span><span class="p">,</span><span class="n">ncols</span><span class="p">)]</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">roi_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">LABELS</span><span class="p">:</span>
            <span class="n">ts_mean</span> <span class="o">=</span> <span class="n">X_conds</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s2">_m&quot;</span><span class="p">][:,</span> <span class="n">idx_roi</span><span class="p">]</span>
            <span class="n">ts_std</span> <span class="o">=</span> <span class="n">X_conds</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s2">_s&quot;</span><span class="p">][:,</span> <span class="n">idx_roi</span><span class="p">]</span>

            <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ts_mean</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">label</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">names</span><span class="p">[</span><span class="n">label</span><span class="p">])</span>

            <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span>
                <span class="n">time</span><span class="p">,</span> 
                <span class="p">(</span><span class="n">ts_mean</span> <span class="o">-</span> <span class="n">ts_std</span><span class="p">),</span> 
                <span class="p">(</span><span class="n">ts_mean</span> <span class="o">+</span> <span class="n">ts_std</span><span class="p">),</span>
                <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">label</span><span class="p">],</span>
            <span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;time&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;roi resp.&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">savefig</span><span class="p">:</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span>
            <span class="n">fig_file</span><span class="p">,</span>
            <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span>
            <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;png&#39;</span><span class="p">,</span>
            <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">,</span>
            <span class="n">transparent</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_samples</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">savefig</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fig_file</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">X_conds</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">LABELS</span><span class="p">:</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">label</span>
        <span class="n">X_conds</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

    <span class="n">roi_name_file</span> <span class="o">=</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;HOME&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">/parcellations/MAX_85_ROI_masks/ROI_names.txt&quot;</span>
    <span class="p">)</span>
    <span class="n">roi_names</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">roi_name_file</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;roi_name&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

    <span class="n">time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;safe&#39;</span><span class="p">,</span> <span class="s1">&#39;threat&#39;</span><span class="p">]</span>
    <span class="n">colors</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="s1">&#39;royalblue&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="s1">&#39;firebrick&#39;</span><span class="p">}</span>
    <span class="n">nrows</span><span class="p">,</span> <span class="n">ncols</span> <span class="o">=</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">5</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span>
        <span class="n">nrows</span><span class="o">=</span><span class="n">nrows</span><span class="p">,</span> 
        <span class="n">ncols</span><span class="o">=</span><span class="n">ncols</span><span class="p">,</span> 
        <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="o">*</span><span class="n">ncols</span><span class="p">,</span> <span class="mi">4</span><span class="o">*</span><span class="n">nrows</span><span class="p">),</span> 
        <span class="n">sharex</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
        <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
        <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span>
    <span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span>
        <span class="n">left</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
        <span class="n">right</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
        <span class="n">wspace</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.5</span>
    <span class="p">)</span>

    <span class="k">for</span> <span class="n">idx_roi</span><span class="p">,</span> <span class="n">roi_name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">roi_names</span><span class="p">):</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="n">idx_roi</span><span class="o">//</span><span class="n">ncols</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mod</span><span class="p">(</span><span class="n">idx_roi</span><span class="p">,</span><span class="n">ncols</span><span class="p">)]</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">roi_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">LABELS</span><span class="p">:</span>
            <span class="n">ts_mean</span> <span class="o">=</span> <span class="n">X_conds</span><span class="p">[</span><span class="n">label</span><span class="p">][:</span><span class="mi">10</span><span class="p">,</span> <span class="p">:,</span> <span class="n">idx_roi</span><span class="p">]</span><span class="o">.</span><span class="n">T</span>

            <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ts_mean</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">label</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;time&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;roi resp.&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># ax.legend()</span>

    <span class="k">if</span> <span class="n">savefig</span><span class="p">:</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span>
            <span class="n">fig_file</span><span class="p">,</span>
            <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span>
            <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;png&#39;</span><span class="p">,</span>
            <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">,</span>
            <span class="n">transparent</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="data">
<h2>data<a class="headerlink" href="#data" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_data</span><span class="p">(</span><span class="n">data_df</span><span class="p">,</span> <span class="n">subj_idx_list</span><span class="p">):</span>
    <span class="n">normalize</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">z</span><span class="p">:</span> <span class="p">(</span><span class="n">z</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">z</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">idx_row</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">subj_idx_list</span><span class="p">):</span>
        <span class="n">subj</span><span class="p">,</span> <span class="n">ts</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">data_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">idx_row</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">LABELS</span><span class="p">:</span>
            <span class="n">contig_regions</span> <span class="o">=</span> <span class="n">dataset_utils</span><span class="o">.</span><span class="n">contiguous_regions</span><span class="p">(</span><span class="n">targets</span> <span class="o">==</span> <span class="n">label</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">region</span> <span class="ow">in</span> <span class="n">contig_regions</span><span class="p">:</span>
                <span class="n">X</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ts</span><span class="p">[</span><span class="n">region</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="n">region</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">:])</span>
                <span class="n">y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">targets</span><span class="p">[</span><span class="n">region</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="n">region</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>

    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">idx_roi</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
        <span class="n">X</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">idx_roi</span><span class="p">]</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">idx_roi</span><span class="p">]))</span>
    
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="c1">#torch.FloatTensor(X).to(device=device), torch.LongTensor(y).to(device=device)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">dataframe</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">max_data_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">proj_dir</span><span class="si">}</span><span class="s2">/data/max/data_df.pkl&quot;</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">max_data_path</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">max_data_df</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">(hyper)-parameters</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="k">class</span> <span class="nc">ARGS</span><span class="p">():</span> <span class="k">pass</span>
<span class="n">args</span> <span class="o">=</span> <span class="n">ARGS</span><span class="p">()</span>

<span class="n">args</span><span class="o">.</span><span class="n">SEED</span> <span class="o">=</span> <span class="mi">74</span>
<span class="n">args</span><span class="o">.</span><span class="n">LABELS</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">args</span><span class="o">.</span><span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;safe&#39;</span><span class="p">,</span> <span class="s1">&#39;threat&#39;</span><span class="p">]</span>
<span class="n">args</span><span class="o">.</span><span class="n">MASK</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span>

<span class="c1"># data</span>
<span class="n">args</span><span class="o">.</span><span class="n">num_subjects</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">max_data_df</span><span class="p">)</span>
<span class="n">args</span><span class="o">.</span><span class="n">num_train</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="mf">0.4</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">num_subjects</span><span class="p">)</span>
<span class="n">args</span><span class="o">.</span><span class="n">num_valid</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="mf">0.3</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">num_subjects</span><span class="p">)</span>
<span class="n">args</span><span class="o">.</span><span class="n">num_test</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">num_subjects</span> <span class="o">-</span> <span class="n">args</span><span class="o">.</span><span class="n">num_train</span> <span class="o">-</span> <span class="n">args</span><span class="o">.</span><span class="n">num_valid</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">generate dataset for the model</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">subject_idx_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_subjects</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">Random</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">SEED</span><span class="p">)</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">subject_idx_list</span><span class="p">)</span>

<span class="n">train_idx_list</span> <span class="o">=</span> <span class="n">subject_idx_list</span><span class="p">[:</span><span class="n">args</span><span class="o">.</span><span class="n">num_train</span><span class="p">]</span>
<span class="n">valid_idx_list</span> <span class="o">=</span> <span class="n">subject_idx_list</span><span class="p">[</span><span class="n">args</span><span class="o">.</span><span class="n">num_train</span> <span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">num_train</span> <span class="o">+</span> <span class="n">args</span><span class="o">.</span><span class="n">num_valid</span><span class="p">]</span>
<span class="n">test_idx_list</span> <span class="o">=</span> <span class="n">subject_idx_list</span><span class="p">[</span><span class="n">args</span><span class="o">.</span><span class="n">num_train</span> <span class="o">+</span> <span class="n">args</span><span class="o">.</span><span class="n">num_valid</span><span class="p">:]</span>

<span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="n">max_data_df</span><span class="p">,</span> <span class="n">train_idx_list</span><span class="p">)</span>
<span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="n">max_data_df</span><span class="p">,</span> <span class="n">valid_idx_list</span><span class="p">)</span> 
<span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="n">max_data_df</span><span class="p">,</span> <span class="n">test_idx_list</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 44/44 [00:00&lt;00:00, 7738.89it/s]
100%|██████████| 33/33 [00:00&lt;00:00, 8088.59it/s]
100%|██████████| 32/32 [00:00&lt;00:00, 2342.86it/s]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># &#39;&#39;&#39;</span>
<span class="c1"># samples of the actual data</span>
<span class="c1"># &#39;&#39;&#39;</span>
<span class="c1"># X, y = X_train, y_train</span>
<span class="c1"># plot_samples(X, y)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">ditribution of error around the mean for each time point</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span>
<span class="n">idx_roi</span> <span class="o">=</span> <span class="mi">45</span>

<span class="n">X_conds</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">LABELS</span><span class="p">:</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">label</span>
    <span class="n">X_conds</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:,</span> <span class="n">idx_roi</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:,</span> <span class="n">idx_roi</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>

<span class="n">time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;safe&#39;</span><span class="p">,</span> <span class="s1">&#39;threat&#39;</span><span class="p">]</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="s1">&#39;royalblue&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="s1">&#39;firebrick&#39;</span><span class="p">}</span>
<span class="n">nrows</span><span class="p">,</span> <span class="n">ncols</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span>
        <span class="n">nrows</span><span class="o">=</span><span class="n">nrows</span><span class="p">,</span> 
        <span class="n">ncols</span><span class="o">=</span><span class="n">ncols</span><span class="p">,</span> 
        <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="o">*</span><span class="n">ncols</span><span class="p">,</span> <span class="mi">4</span><span class="o">*</span><span class="n">nrows</span><span class="p">),</span> 
        <span class="n">sharex</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
        <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
        <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span>
    <span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span>
    <span class="n">left</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
    <span class="n">right</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
    <span class="n">wspace</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.5</span>
<span class="p">)</span>

<span class="k">for</span> <span class="n">idx_tp</span><span class="p">,</span> <span class="n">tp</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">time</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="n">idx_tp</span><span class="o">//</span><span class="n">ncols</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mod</span><span class="p">(</span><span class="n">idx_tp</span><span class="p">,</span><span class="n">ncols</span><span class="p">)]</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;time point: </span><span class="si">{</span><span class="n">tp</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">LABELS</span><span class="p">:</span>
        
        <span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="n">X_conds</span><span class="p">[</span><span class="n">label</span><span class="p">][:,</span> <span class="n">idx_tp</span><span class="p">],</span>
            <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
            <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">label</span><span class="p">],</span>
            <span class="n">label</span><span class="o">=</span><span class="n">names</span><span class="p">[</span><span class="n">label</span><span class="p">],</span>
            <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span>
        <span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/01-simulated_data_white_noise_11_0.png" src="../../_images/01-simulated_data_white_noise_11_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">white-noise </span>
<span class="sd">-----------</span>
<span class="sd">1. std&#39;s for each roi and each tp</span>
<span class="sd">2. simulated data with i.i.d. normal noise (white noise) around mean time series</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="k">def</span> <span class="nf">sim_data_white_additive_noise</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">noise_level</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="n">X_</span><span class="p">,</span> <span class="n">y_</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">LABELS</span><span class="p">:</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">label</span>
        <span class="n">X_</span> <span class="o">+=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span>
            <span class="n">loc</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> 
            <span class="n">scale</span><span class="o">=</span><span class="n">noise_level</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> 
            <span class="n">size</span><span class="o">=</span><span class="n">X</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
        <span class="p">)]</span>
        <span class="n">y_</span> <span class="o">+=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span> <span class="o">*</span> <span class="n">label</span><span class="p">]</span>

    <span class="n">X_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">X_</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">y_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">y_</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">y_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">X_</span> <span class="o">=</span> <span class="n">X_</span><span class="p">[</span><span class="n">perm</span><span class="p">]</span>
    <span class="n">y_</span> <span class="o">=</span> <span class="n">y_</span><span class="p">[</span><span class="n">perm</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">X_</span><span class="p">,</span> <span class="n">y_</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_</span><span class="p">,</span> <span class="n">y_train_</span> <span class="o">=</span> <span class="n">sim_data_white_additive_noise</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">X_valid_</span><span class="p">,</span> <span class="n">y_valid_</span> <span class="o">=</span> <span class="n">sim_data_white_additive_noise</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span>
<span class="n">X_test_</span><span class="p">,</span> <span class="n">y_test_</span> <span class="o">=</span> <span class="n">sim_data_white_additive_noise</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_roi_time_series</span><span class="p">(</span><span class="n">X_train_</span><span class="p">,</span> <span class="n">y_train_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/01-simulated_data_white_noise_14_0.png" src="../../_images/01-simulated_data_white_noise_14_0.png" />
</div>
</div>
</div>
<div class="section" id="models">
<h2>models<a class="headerlink" href="#models" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">model</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">args</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">X_train_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">args</span><span class="o">.</span><span class="n">out_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">LABELS</span><span class="p">)</span>
<span class="n">args</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">args</span><span class="o">.</span><span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">args</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="c1"># args.num_classes = len(args.LABELS)</span>
<span class="n">args</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.5</span>

<span class="k">class</span> <span class="nc">GRU_classifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GRU_classifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span>
            <span class="n">input_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">input_dim</span><span class="p">,</span>
            <span class="n">hidden_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">dropout</span>
        <span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">out_dim</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">dropout</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

    <span class="c1"># def initHidden(self, args):</span>
        <span class="c1"># return torch.zeros(1, args.batch_size, args.num_units, device=device)</span>

    <span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">):</span>
        <span class="n">labels_pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_true</span> <span class="o">!=</span> <span class="n">args</span><span class="o">.</span><span class="n">MASK</span><span class="p">)</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">labels_pred</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">-</span> <span class="n">y_true</span><span class="p">[</span><span class="n">mask</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">correct</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">correct</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">GRU_classifier</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>

<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">MASK</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>

<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">criterion</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">X_train_</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">y_train_</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">X_valid_</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">y_valid_</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">X_test_</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">y_test_</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">permut_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">X_train_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">permut_valid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">X_valid_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">model</span><span class="p">,</span> <span class="n">best_model</span><span class="p">,</span> <span class="n">history</span><span class="p">,</span> <span class="n">best_epoch</span> <span class="o">=</span> <span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
<span class="n">plot_training_history</span><span class="p">(</span><span class="n">history</span><span class="p">,</span> <span class="n">best_epoch</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;valid: </span><span class="si">{</span><span class="n">evaluate</span><span class="p">(</span><span class="n">best_model</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">permut_valid</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">permut_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">X_test_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;test: </span><span class="si">{</span><span class="n">evaluate</span><span class="p">(</span><span class="n">best_model</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">permut_test</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/govindas/venvs/expln-ai3.9/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1
  warnings.warn(&quot;dropout option adds dropout after all but last &quot;
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 01
	Train Loss: 0.731 | Train Acc: 50.33%
	 Val. Loss: 0.702 |  Val. Acc: 52.33%
Epoch: 02
	Train Loss: 0.706 | Train Acc: 52.51%
	 Val. Loss: 0.688 |  Val. Acc: 54.67%
Epoch: 03
	Train Loss: 0.693 | Train Acc: 54.37%
	 Val. Loss: 0.677 |  Val. Acc: 56.96%
Epoch: 04
	Train Loss: 0.676 | Train Acc: 57.03%
	 Val. Loss: 0.666 |  Val. Acc: 59.91%
Epoch: 05
	Train Loss: 0.666 | Train Acc: 58.76%
	 Val. Loss: 0.654 |  Val. Acc: 62.43%
Epoch: 06
	Train Loss: 0.654 | Train Acc: 61.07%
	 Val. Loss: 0.641 |  Val. Acc: 64.33%
Epoch: 07
	Train Loss: 0.638 | Train Acc: 63.60%
	 Val. Loss: 0.627 |  Val. Acc: 66.01%
Epoch: 08
	Train Loss: 0.621 | Train Acc: 65.78%
	 Val. Loss: 0.610 |  Val. Acc: 67.51%
Epoch: 09
	Train Loss: 0.600 | Train Acc: 67.93%
	 Val. Loss: 0.591 |  Val. Acc: 69.12%
Epoch: 10
	Train Loss: 0.578 | Train Acc: 70.25%
	 Val. Loss: 0.572 |  Val. Acc: 70.68%
Epoch: 11
	Train Loss: 0.558 | Train Acc: 71.68%
	 Val. Loss: 0.552 |  Val. Acc: 72.17%
Epoch: 12
	Train Loss: 0.537 | Train Acc: 73.32%
	 Val. Loss: 0.533 |  Val. Acc: 73.48%
Epoch: 13
	Train Loss: 0.514 | Train Acc: 75.42%
	 Val. Loss: 0.515 |  Val. Acc: 74.59%
Epoch: 14
	Train Loss: 0.493 | Train Acc: 76.54%
	 Val. Loss: 0.498 |  Val. Acc: 75.58%
Epoch: 15
	Train Loss: 0.471 | Train Acc: 78.01%
	 Val. Loss: 0.484 |  Val. Acc: 76.37%
Epoch: 16
	Train Loss: 0.457 | Train Acc: 78.92%
	 Val. Loss: 0.473 |  Val. Acc: 76.94%
Epoch: 17
	Train Loss: 0.439 | Train Acc: 80.03%
	 Val. Loss: 0.463 |  Val. Acc: 77.42%
Epoch: 18
	Train Loss: 0.425 | Train Acc: 81.07%
	 Val. Loss: 0.457 |  Val. Acc: 77.88%
Epoch: 19
	Train Loss: 0.415 | Train Acc: 81.30%
	 Val. Loss: 0.454 |  Val. Acc: 78.14%
Epoch: 20
	Train Loss: 0.400 | Train Acc: 82.19%
	 Val. Loss: 0.452 |  Val. Acc: 78.26%
Epoch: 21
	Train Loss: 0.390 | Train Acc: 82.79%
	 Val. Loss: 0.451 |  Val. Acc: 78.35%
Epoch: 22
	Train Loss: 0.379 | Train Acc: 83.20%
	 Val. Loss: 0.452 |  Val. Acc: 78.47%
Epoch: 23
	Train Loss: 0.369 | Train Acc: 83.68%
	 Val. Loss: 0.454 |  Val. Acc: 78.63%
Epoch: 24
	Train Loss: 0.362 | Train Acc: 84.13%
	 Val. Loss: 0.457 |  Val. Acc: 78.72%
Epoch: 25
	Train Loss: 0.351 | Train Acc: 84.77%
	 Val. Loss: 0.461 |  Val. Acc: 78.60%
Epoch: 26
	Train Loss: 0.345 | Train Acc: 84.96%
	 Val. Loss: 0.467 |  Val. Acc: 78.45%
Epoch: 27
	Train Loss: 0.337 | Train Acc: 85.23%
	 Val. Loss: 0.473 |  Val. Acc: 78.39%
Epoch: 28
	Train Loss: 0.330 | Train Acc: 85.74%
	 Val. Loss: 0.478 |  Val. Acc: 78.29%
Epoch: 29
	Train Loss: 0.326 | Train Acc: 85.81%
	 Val. Loss: 0.485 |  Val. Acc: 78.06%
Epoch: 30
	Train Loss: 0.318 | Train Acc: 86.48%
	 Val. Loss: 0.492 |  Val. Acc: 77.82%
Epoch: 31
	Train Loss: 0.311 | Train Acc: 86.90%
	 Val. Loss: 0.501 |  Val. Acc: 77.45%
Epoch: 32
	Train Loss: 0.303 | Train Acc: 86.97%
	 Val. Loss: 0.511 |  Val. Acc: 77.20%
Epoch: 33
	Train Loss: 0.299 | Train Acc: 87.21%
	 Val. Loss: 0.522 |  Val. Acc: 77.02%
Epoch: 34
	Train Loss: 0.290 | Train Acc: 87.59%
	 Val. Loss: 0.534 |  Val. Acc: 76.83%
Epoch: 35
	Train Loss: 0.283 | Train Acc: 87.87%
	 Val. Loss: 0.546 |  Val. Acc: 76.54%
Epoch: 36
	Train Loss: 0.275 | Train Acc: 88.29%
	 Val. Loss: 0.559 |  Val. Acc: 76.36%
Epoch: 37
	Train Loss: 0.275 | Train Acc: 88.28%
	 Val. Loss: 0.572 |  Val. Acc: 76.14%
Epoch: 38
	Train Loss: 0.267 | Train Acc: 88.79%
	 Val. Loss: 0.586 |  Val. Acc: 75.94%
Epoch: 39
	Train Loss: 0.258 | Train Acc: 88.96%
	 Val. Loss: 0.600 |  Val. Acc: 75.90%
Epoch: 40
	Train Loss: 0.258 | Train Acc: 89.07%
	 Val. Loss: 0.615 |  Val. Acc: 75.74%
Epoch: 41
	Train Loss: 0.252 | Train Acc: 89.33%
	 Val. Loss: 0.628 |  Val. Acc: 75.45%
Epoch: 42
	Train Loss: 0.247 | Train Acc: 89.76%
	 Val. Loss: 0.642 |  Val. Acc: 75.14%
Epoch: 43
	Train Loss: 0.243 | Train Acc: 89.66%
	 Val. Loss: 0.657 |  Val. Acc: 75.00%
Epoch: 44
	Train Loss: 0.239 | Train Acc: 89.85%
	 Val. Loss: 0.672 |  Val. Acc: 74.72%
Epoch: 45
	Train Loss: 0.235 | Train Acc: 90.05%
	 Val. Loss: 0.688 |  Val. Acc: 74.47%
Epoch: 46
	Train Loss: 0.231 | Train Acc: 90.06%
	 Val. Loss: 0.707 |  Val. Acc: 74.23%
Epoch: 47
	Train Loss: 0.226 | Train Acc: 90.56%
	 Val. Loss: 0.726 |  Val. Acc: 73.90%
Epoch: 48
	Train Loss: 0.225 | Train Acc: 90.50%
	 Val. Loss: 0.742 |  Val. Acc: 73.73%
Epoch: 49
	Train Loss: 0.219 | Train Acc: 90.85%
	 Val. Loss: 0.760 |  Val. Acc: 73.35%
Epoch: 50
	Train Loss: 0.216 | Train Acc: 90.81%
	 Val. Loss: 0.781 |  Val. Acc: 73.10%
Epoch: 51
	Train Loss: 0.213 | Train Acc: 90.92%
	 Val. Loss: 0.799 |  Val. Acc: 73.03%
Epoch: 52
	Train Loss: 0.209 | Train Acc: 91.06%
	 Val. Loss: 0.821 |  Val. Acc: 72.80%
Epoch: 53
	Train Loss: 0.205 | Train Acc: 91.30%
	 Val. Loss: 0.842 |  Val. Acc: 72.67%
Epoch: 54
	Train Loss: 0.203 | Train Acc: 91.28%
	 Val. Loss: 0.867 |  Val. Acc: 72.48%
Epoch: 55
	Train Loss: 0.198 | Train Acc: 91.55%
	 Val. Loss: 0.888 |  Val. Acc: 72.29%
Epoch: 56
	Train Loss: 0.197 | Train Acc: 91.65%
	 Val. Loss: 0.910 |  Val. Acc: 72.08%
Epoch: 57
	Train Loss: 0.192 | Train Acc: 91.91%
	 Val. Loss: 0.926 |  Val. Acc: 71.92%
Epoch: 58
	Train Loss: 0.189 | Train Acc: 92.01%
	 Val. Loss: 0.945 |  Val. Acc: 71.92%
Epoch: 59
	Train Loss: 0.190 | Train Acc: 92.02%
	 Val. Loss: 0.968 |  Val. Acc: 71.57%
Epoch: 60
	Train Loss: 0.186 | Train Acc: 92.13%
	 Val. Loss: 0.989 |  Val. Acc: 71.37%
Epoch: 61
	Train Loss: 0.183 | Train Acc: 92.23%
	 Val. Loss: 1.009 |  Val. Acc: 71.21%
Epoch: 62
	Train Loss: 0.181 | Train Acc: 92.13%
	 Val. Loss: 1.026 |  Val. Acc: 71.07%
Epoch: 63
	Train Loss: 0.179 | Train Acc: 92.49%
	 Val. Loss: 1.051 |  Val. Acc: 70.87%
Epoch: 64
	Train Loss: 0.172 | Train Acc: 92.99%
	 Val. Loss: 1.081 |  Val. Acc: 70.58%
Epoch: 65
	Train Loss: 0.167 | Train Acc: 92.99%
	 Val. Loss: 1.111 |  Val. Acc: 70.21%
Epoch: 66
	Train Loss: 0.170 | Train Acc: 92.97%
	 Val. Loss: 1.130 |  Val. Acc: 70.09%
Epoch: 67
	Train Loss: 0.162 | Train Acc: 93.11%
	 Val. Loss: 1.155 |  Val. Acc: 70.11%
Epoch: 68
	Train Loss: 0.163 | Train Acc: 93.06%
	 Val. Loss: 1.179 |  Val. Acc: 69.86%
Epoch: 69
	Train Loss: 0.160 | Train Acc: 93.29%
	 Val. Loss: 1.204 |  Val. Acc: 69.61%
Epoch: 70
	Train Loss: 0.158 | Train Acc: 93.17%
	 Val. Loss: 1.228 |  Val. Acc: 69.39%
Epoch: 71
	Train Loss: 0.153 | Train Acc: 93.51%
	 Val. Loss: 1.258 |  Val. Acc: 69.17%
Epoch: 72
	Train Loss: 0.154 | Train Acc: 93.39%
	 Val. Loss: 1.289 |  Val. Acc: 68.79%
Epoch: 73
	Train Loss: 0.146 | Train Acc: 93.95%
	 Val. Loss: 1.325 |  Val. Acc: 68.63%
Epoch: 74
	Train Loss: 0.144 | Train Acc: 93.90%
	 Val. Loss: 1.350 |  Val. Acc: 68.55%
Epoch: 75
	Train Loss: 0.147 | Train Acc: 93.82%
	 Val. Loss: 1.373 |  Val. Acc: 68.39%
Epoch: 76
	Train Loss: 0.143 | Train Acc: 93.97%
	 Val. Loss: 1.391 |  Val. Acc: 68.27%
Epoch: 77
	Train Loss: 0.139 | Train Acc: 94.03%
	 Val. Loss: 1.417 |  Val. Acc: 68.06%
Epoch: 78
	Train Loss: 0.134 | Train Acc: 94.42%
	 Val. Loss: 1.443 |  Val. Acc: 67.81%
Epoch: 79
	Train Loss: 0.136 | Train Acc: 94.28%
	 Val. Loss: 1.473 |  Val. Acc: 67.51%
Epoch: 80
	Train Loss: 0.137 | Train Acc: 94.03%
	 Val. Loss: 1.499 |  Val. Acc: 67.40%
Epoch: 81
	Train Loss: 0.134 | Train Acc: 94.31%
	 Val. Loss: 1.523 |  Val. Acc: 67.19%
Epoch: 82
	Train Loss: 0.133 | Train Acc: 94.17%
	 Val. Loss: 1.546 |  Val. Acc: 67.14%
Epoch: 83
	Train Loss: 0.129 | Train Acc: 94.40%
	 Val. Loss: 1.578 |  Val. Acc: 66.73%
Epoch: 84
	Train Loss: 0.131 | Train Acc: 94.46%
	 Val. Loss: 1.596 |  Val. Acc: 66.79%
Epoch: 85
	Train Loss: 0.128 | Train Acc: 94.51%
	 Val. Loss: 1.623 |  Val. Acc: 66.72%
Epoch: 86
	Train Loss: 0.127 | Train Acc: 94.47%
	 Val. Loss: 1.653 |  Val. Acc: 66.37%
Epoch: 87
	Train Loss: 0.127 | Train Acc: 94.48%
	 Val. Loss: 1.673 |  Val. Acc: 66.34%
Epoch: 88
	Train Loss: 0.127 | Train Acc: 94.50%
	 Val. Loss: 1.696 |  Val. Acc: 66.17%
Epoch: 89
	Train Loss: 0.121 | Train Acc: 94.84%
	 Val. Loss: 1.723 |  Val. Acc: 66.21%
Epoch: 90
	Train Loss: 0.120 | Train Acc: 94.79%
	 Val. Loss: 1.747 |  Val. Acc: 66.11%
Epoch: 91
	Train Loss: 0.122 | Train Acc: 94.92%
	 Val. Loss: 1.769 |  Val. Acc: 65.95%
Epoch: 92
	Train Loss: 0.117 | Train Acc: 94.93%
	 Val. Loss: 1.787 |  Val. Acc: 65.91%
Epoch: 93
	Train Loss: 0.114 | Train Acc: 95.02%
	 Val. Loss: 1.807 |  Val. Acc: 65.94%
Epoch: 94
	Train Loss: 0.113 | Train Acc: 95.17%
	 Val. Loss: 1.827 |  Val. Acc: 65.78%
Epoch: 95
	Train Loss: 0.113 | Train Acc: 95.13%
	 Val. Loss: 1.847 |  Val. Acc: 65.76%
Epoch: 96
	Train Loss: 0.115 | Train Acc: 95.12%
	 Val. Loss: 1.862 |  Val. Acc: 65.77%
Epoch: 97
	Train Loss: 0.111 | Train Acc: 95.17%
	 Val. Loss: 1.885 |  Val. Acc: 65.77%
Epoch: 98
	Train Loss: 0.114 | Train Acc: 95.13%
	 Val. Loss: 1.904 |  Val. Acc: 65.86%
Epoch: 99
	Train Loss: 0.107 | Train Acc: 95.39%
	 Val. Loss: 1.925 |  Val. Acc: 65.72%
Epoch: 100
	Train Loss: 0.108 | Train Acc: 95.16%
	 Val. Loss: 1.946 |  Val. Acc: 65.61%
valid: (0.4511216264218092, 0.7835120670497417)
test: (0.5774261467158794, 0.7091936692595482)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/govindas/venvs/expln-ai3.9/lib/python3.9/site-packages/torch/nn/modules/rnn.py:942: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  ../aten/src/ATen/native/cudnn/RNN.cpp:926.)
  result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,
</pre></div>
</div>
<img alt="../../_images/01-simulated_data_white_noise_16_3.png" src="../../_images/01-simulated_data_white_noise_16_3.png" />
</div>
</div>
<p>GRU model fits the data with ~79% accuracy on validation data.
GRU model with either 8 units, or 16 units, or 32 units overfits on the training data and reaches ~79% on validation data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">reduce noise level and see model performance.</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">data with reduced noise level</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">nl</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">X_train_</span><span class="p">,</span> <span class="n">y_train_</span> <span class="o">=</span> <span class="n">sim_data_white_additive_noise</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">noise_level</span><span class="o">=</span><span class="n">nl</span><span class="p">)</span>
<span class="n">X_valid_</span><span class="p">,</span> <span class="n">y_valid_</span> <span class="o">=</span> <span class="n">sim_data_white_additive_noise</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">,</span> <span class="n">noise_level</span><span class="o">=</span><span class="n">nl</span><span class="p">)</span>
<span class="n">X_test_</span><span class="p">,</span> <span class="n">y_test_</span> <span class="o">=</span> <span class="n">sim_data_white_additive_noise</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">noise_level</span><span class="o">=</span><span class="n">nl</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">model</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">args</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">X_train_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">args</span><span class="o">.</span><span class="n">out_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">LABELS</span><span class="p">)</span>
<span class="n">args</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">args</span><span class="o">.</span><span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">args</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="c1"># args.num_classes = len(args.LABELS)</span>
<span class="n">args</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.5</span>

<span class="k">class</span> <span class="nc">GRU_classifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GRU_classifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span>
            <span class="n">input_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">input_dim</span><span class="p">,</span>
            <span class="n">hidden_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">dropout</span>
        <span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">out_dim</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">dropout</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

    <span class="c1"># def initHidden(self, args):</span>
        <span class="c1"># return torch.zeros(1, args.batch_size, args.num_units, device=device)</span>

    <span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">):</span>
        <span class="n">labels_pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_true</span> <span class="o">!=</span> <span class="n">args</span><span class="o">.</span><span class="n">MASK</span><span class="p">)</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">labels_pred</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">-</span> <span class="n">y_true</span><span class="p">[</span><span class="n">mask</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">correct</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">correct</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">GRU_classifier</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>

<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">MASK</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>

<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">criterion</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">X_train_</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">y_train_</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">X_valid_</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">y_valid_</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">X_test_</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">y_test_</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">permut_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">X_train_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">permut_valid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">X_valid_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">model</span><span class="p">,</span> <span class="n">best_model</span><span class="p">,</span> <span class="n">history</span><span class="p">,</span> <span class="n">best_epoch</span> <span class="o">=</span> <span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
<span class="n">plot_training_history</span><span class="p">(</span><span class="n">history</span><span class="p">,</span> <span class="n">best_epoch</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;valid: </span><span class="si">{</span><span class="n">evaluate</span><span class="p">(</span><span class="n">best_model</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">permut_valid</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">permut_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">X_test_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;test: </span><span class="si">{</span><span class="n">evaluate</span><span class="p">(</span><span class="n">best_model</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">permut_test</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/govindas/venvs/expln-ai3.9/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1
  warnings.warn(&quot;dropout option adds dropout after all but last &quot;
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 01
	Train Loss: 0.756 | Train Acc: 48.43%
	 Val. Loss: 0.720 |  Val. Acc: 50.53%
Epoch: 02
	Train Loss: 0.707 | Train Acc: 52.80%
	 Val. Loss: 0.677 |  Val. Acc: 57.64%
Epoch: 03
	Train Loss: 0.662 | Train Acc: 59.14%
	 Val. Loss: 0.633 |  Val. Acc: 67.32%
Epoch: 04
	Train Loss: 0.615 | Train Acc: 66.48%
	 Val. Loss: 0.583 |  Val. Acc: 74.65%
Epoch: 05
	Train Loss: 0.561 | Train Acc: 73.36%
	 Val. Loss: 0.525 |  Val. Acc: 79.31%
Epoch: 06
	Train Loss: 0.503 | Train Acc: 77.97%
	 Val. Loss: 0.463 |  Val. Acc: 82.83%
Epoch: 07
	Train Loss: 0.442 | Train Acc: 81.44%
	 Val. Loss: 0.402 |  Val. Acc: 85.18%
Epoch: 08
	Train Loss: 0.386 | Train Acc: 84.62%
	 Val. Loss: 0.347 |  Val. Acc: 86.97%
Epoch: 09
	Train Loss: 0.340 | Train Acc: 86.31%
	 Val. Loss: 0.301 |  Val. Acc: 88.39%
Epoch: 10
	Train Loss: 0.300 | Train Acc: 88.05%
	 Val. Loss: 0.266 |  Val. Acc: 89.65%
Epoch: 11
	Train Loss: 0.267 | Train Acc: 89.46%
	 Val. Loss: 0.240 |  Val. Acc: 90.43%
Epoch: 12
	Train Loss: 0.245 | Train Acc: 90.21%
	 Val. Loss: 0.221 |  Val. Acc: 91.00%
Epoch: 13
	Train Loss: 0.230 | Train Acc: 90.89%
	 Val. Loss: 0.208 |  Val. Acc: 91.26%
Epoch: 14
	Train Loss: 0.214 | Train Acc: 91.57%
	 Val. Loss: 0.200 |  Val. Acc: 91.39%
Epoch: 15
	Train Loss: 0.202 | Train Acc: 92.10%
	 Val. Loss: 0.195 |  Val. Acc: 91.42%
Epoch: 16
	Train Loss: 0.191 | Train Acc: 92.52%
	 Val. Loss: 0.191 |  Val. Acc: 91.61%
Epoch: 17
	Train Loss: 0.181 | Train Acc: 93.01%
	 Val. Loss: 0.188 |  Val. Acc: 91.69%
Epoch: 18
	Train Loss: 0.177 | Train Acc: 93.07%
	 Val. Loss: 0.187 |  Val. Acc: 91.74%
Epoch: 19
	Train Loss: 0.168 | Train Acc: 93.42%
	 Val. Loss: 0.187 |  Val. Acc: 91.80%
Epoch: 20
	Train Loss: 0.164 | Train Acc: 93.59%
	 Val. Loss: 0.186 |  Val. Acc: 91.85%
Epoch: 21
	Train Loss: 0.157 | Train Acc: 93.79%
	 Val. Loss: 0.188 |  Val. Acc: 91.80%
Epoch: 22
	Train Loss: 0.153 | Train Acc: 93.88%
	 Val. Loss: 0.189 |  Val. Acc: 91.80%
Epoch: 23
	Train Loss: 0.150 | Train Acc: 94.08%
	 Val. Loss: 0.189 |  Val. Acc: 91.79%
Epoch: 24
	Train Loss: 0.144 | Train Acc: 94.53%
	 Val. Loss: 0.191 |  Val. Acc: 91.76%
Epoch: 25
	Train Loss: 0.141 | Train Acc: 94.30%
	 Val. Loss: 0.193 |  Val. Acc: 91.74%
Epoch: 26
	Train Loss: 0.138 | Train Acc: 94.46%
	 Val. Loss: 0.198 |  Val. Acc: 91.67%
Epoch: 27
	Train Loss: 0.134 | Train Acc: 94.71%
	 Val. Loss: 0.203 |  Val. Acc: 91.51%
Epoch: 28
	Train Loss: 0.133 | Train Acc: 95.00%
	 Val. Loss: 0.208 |  Val. Acc: 91.42%
Epoch: 29
	Train Loss: 0.130 | Train Acc: 94.84%
	 Val. Loss: 0.213 |  Val. Acc: 91.30%
Epoch: 30
	Train Loss: 0.127 | Train Acc: 94.89%
	 Val. Loss: 0.221 |  Val. Acc: 91.11%
Epoch: 31
	Train Loss: 0.125 | Train Acc: 95.09%
	 Val. Loss: 0.226 |  Val. Acc: 91.00%
Epoch: 32
	Train Loss: 0.120 | Train Acc: 95.23%
	 Val. Loss: 0.236 |  Val. Acc: 90.87%
Epoch: 33
	Train Loss: 0.120 | Train Acc: 95.06%
	 Val. Loss: 0.243 |  Val. Acc: 90.84%
Epoch: 34
	Train Loss: 0.112 | Train Acc: 95.51%
	 Val. Loss: 0.251 |  Val. Acc: 90.74%
Epoch: 35
	Train Loss: 0.115 | Train Acc: 95.47%
	 Val. Loss: 0.260 |  Val. Acc: 90.58%
Epoch: 36
	Train Loss: 0.111 | Train Acc: 95.44%
	 Val. Loss: 0.268 |  Val. Acc: 90.44%
Epoch: 37
	Train Loss: 0.111 | Train Acc: 95.56%
	 Val. Loss: 0.278 |  Val. Acc: 90.31%
Epoch: 38
	Train Loss: 0.108 | Train Acc: 95.62%
	 Val. Loss: 0.288 |  Val. Acc: 90.08%
Epoch: 39
	Train Loss: 0.108 | Train Acc: 95.68%
	 Val. Loss: 0.292 |  Val. Acc: 90.13%
Epoch: 40
	Train Loss: 0.105 | Train Acc: 95.70%
	 Val. Loss: 0.306 |  Val. Acc: 89.83%
Epoch: 41
	Train Loss: 0.103 | Train Acc: 95.94%
	 Val. Loss: 0.318 |  Val. Acc: 89.57%
Epoch: 42
	Train Loss: 0.103 | Train Acc: 95.86%
	 Val. Loss: 0.342 |  Val. Acc: 89.03%
Epoch: 43
	Train Loss: 0.101 | Train Acc: 95.85%
	 Val. Loss: 0.359 |  Val. Acc: 88.80%
Epoch: 44
	Train Loss: 0.098 | Train Acc: 96.00%
	 Val. Loss: 0.371 |  Val. Acc: 88.71%
Epoch: 45
	Train Loss: 0.096 | Train Acc: 96.20%
	 Val. Loss: 0.403 |  Val. Acc: 88.29%
Epoch: 46
	Train Loss: 0.095 | Train Acc: 96.05%
	 Val. Loss: 0.413 |  Val. Acc: 88.23%
Epoch: 47
	Train Loss: 0.094 | Train Acc: 96.05%
	 Val. Loss: 0.437 |  Val. Acc: 87.94%
Epoch: 48
	Train Loss: 0.093 | Train Acc: 96.23%
	 Val. Loss: 0.457 |  Val. Acc: 87.58%
Epoch: 49
	Train Loss: 0.094 | Train Acc: 96.18%
	 Val. Loss: 0.471 |  Val. Acc: 87.48%
Epoch: 50
	Train Loss: 0.093 | Train Acc: 96.11%
	 Val. Loss: 0.495 |  Val. Acc: 87.07%
Epoch: 51
	Train Loss: 0.089 | Train Acc: 96.30%
	 Val. Loss: 0.509 |  Val. Acc: 86.97%
Epoch: 52
	Train Loss: 0.086 | Train Acc: 96.49%
	 Val. Loss: 0.531 |  Val. Acc: 86.67%
Epoch: 53
	Train Loss: 0.085 | Train Acc: 96.49%
	 Val. Loss: 0.557 |  Val. Acc: 86.33%
Epoch: 54
	Train Loss: 0.084 | Train Acc: 96.49%
	 Val. Loss: 0.578 |  Val. Acc: 86.15%
Epoch: 55
	Train Loss: 0.085 | Train Acc: 96.53%
	 Val. Loss: 0.613 |  Val. Acc: 85.74%
Epoch: 56
	Train Loss: 0.082 | Train Acc: 96.66%
	 Val. Loss: 0.628 |  Val. Acc: 85.64%
Epoch: 57
	Train Loss: 0.080 | Train Acc: 96.67%
	 Val. Loss: 0.652 |  Val. Acc: 85.50%
Epoch: 58
	Train Loss: 0.080 | Train Acc: 96.85%
	 Val. Loss: 0.676 |  Val. Acc: 85.34%
Epoch: 59
	Train Loss: 0.080 | Train Acc: 96.74%
	 Val. Loss: 0.692 |  Val. Acc: 85.25%
Epoch: 60
	Train Loss: 0.079 | Train Acc: 96.82%
	 Val. Loss: 0.704 |  Val. Acc: 85.22%
Epoch: 61
	Train Loss: 0.078 | Train Acc: 96.89%
	 Val. Loss: 0.724 |  Val. Acc: 85.04%
Epoch: 62
	Train Loss: 0.077 | Train Acc: 96.86%
	 Val. Loss: 0.747 |  Val. Acc: 84.82%
Epoch: 63
	Train Loss: 0.077 | Train Acc: 96.81%
	 Val. Loss: 0.777 |  Val. Acc: 84.56%
Epoch: 64
	Train Loss: 0.076 | Train Acc: 96.84%
	 Val. Loss: 0.810 |  Val. Acc: 84.18%
Epoch: 65
	Train Loss: 0.076 | Train Acc: 96.88%
	 Val. Loss: 0.818 |  Val. Acc: 84.20%
Epoch: 66
	Train Loss: 0.072 | Train Acc: 96.99%
	 Val. Loss: 0.846 |  Val. Acc: 83.94%
Epoch: 67
	Train Loss: 0.072 | Train Acc: 97.01%
	 Val. Loss: 0.868 |  Val. Acc: 83.77%
Epoch: 68
	Train Loss: 0.071 | Train Acc: 97.00%
	 Val. Loss: 0.891 |  Val. Acc: 83.61%
Epoch: 69
	Train Loss: 0.073 | Train Acc: 97.05%
	 Val. Loss: 0.901 |  Val. Acc: 83.57%
Epoch: 70
	Train Loss: 0.072 | Train Acc: 96.95%
	 Val. Loss: 0.907 |  Val. Acc: 83.58%
Epoch: 71
	Train Loss: 0.068 | Train Acc: 97.24%
	 Val. Loss: 0.938 |  Val. Acc: 83.27%
Epoch: 72
	Train Loss: 0.069 | Train Acc: 97.22%
	 Val. Loss: 0.963 |  Val. Acc: 83.05%
Epoch: 73
	Train Loss: 0.068 | Train Acc: 97.23%
	 Val. Loss: 0.973 |  Val. Acc: 82.95%
Epoch: 74
	Train Loss: 0.067 | Train Acc: 97.26%
	 Val. Loss: 1.001 |  Val. Acc: 82.66%
Epoch: 75
	Train Loss: 0.068 | Train Acc: 97.07%
	 Val. Loss: 1.011 |  Val. Acc: 82.67%
Epoch: 76
	Train Loss: 0.066 | Train Acc: 97.20%
	 Val. Loss: 1.050 |  Val. Acc: 82.34%
Epoch: 77
	Train Loss: 0.067 | Train Acc: 97.15%
	 Val. Loss: 1.074 |  Val. Acc: 82.20%
Epoch: 78
	Train Loss: 0.066 | Train Acc: 97.24%
	 Val. Loss: 1.084 |  Val. Acc: 82.10%
Epoch: 79
	Train Loss: 0.064 | Train Acc: 97.33%
	 Val. Loss: 1.093 |  Val. Acc: 82.04%
Epoch: 80
	Train Loss: 0.063 | Train Acc: 97.50%
	 Val. Loss: 1.122 |  Val. Acc: 81.80%
Epoch: 81
	Train Loss: 0.065 | Train Acc: 97.26%
	 Val. Loss: 1.121 |  Val. Acc: 81.88%
Epoch: 82
	Train Loss: 0.061 | Train Acc: 97.48%
	 Val. Loss: 1.145 |  Val. Acc: 81.73%
Epoch: 83
	Train Loss: 0.062 | Train Acc: 97.48%
	 Val. Loss: 1.169 |  Val. Acc: 81.48%
Epoch: 84
	Train Loss: 0.061 | Train Acc: 97.48%
	 Val. Loss: 1.184 |  Val. Acc: 81.52%
Epoch: 85
	Train Loss: 0.061 | Train Acc: 97.42%
	 Val. Loss: 1.211 |  Val. Acc: 81.21%
Epoch: 86
	Train Loss: 0.060 | Train Acc: 97.50%
	 Val. Loss: 1.233 |  Val. Acc: 81.10%
Epoch: 87
	Train Loss: 0.060 | Train Acc: 97.63%
	 Val. Loss: 1.265 |  Val. Acc: 80.79%
Epoch: 88
	Train Loss: 0.061 | Train Acc: 97.41%
	 Val. Loss: 1.274 |  Val. Acc: 80.84%
Epoch: 89
	Train Loss: 0.058 | Train Acc: 97.63%
	 Val. Loss: 1.274 |  Val. Acc: 81.00%
Epoch: 90
	Train Loss: 0.058 | Train Acc: 97.59%
	 Val. Loss: 1.316 |  Val. Acc: 80.51%
Epoch: 91
	Train Loss: 0.057 | Train Acc: 97.55%
	 Val. Loss: 1.353 |  Val. Acc: 80.08%
Epoch: 92
	Train Loss: 0.059 | Train Acc: 97.64%
	 Val. Loss: 1.379 |  Val. Acc: 79.91%
Epoch: 93
	Train Loss: 0.058 | Train Acc: 97.64%
	 Val. Loss: 1.395 |  Val. Acc: 79.87%
Epoch: 94
	Train Loss: 0.056 | Train Acc: 97.68%
	 Val. Loss: 1.381 |  Val. Acc: 80.15%
Epoch: 95
	Train Loss: 0.058 | Train Acc: 97.57%
	 Val. Loss: 1.395 |  Val. Acc: 80.05%
Epoch: 96
	Train Loss: 0.056 | Train Acc: 97.68%
	 Val. Loss: 1.442 |  Val. Acc: 79.58%
Epoch: 97
	Train Loss: 0.055 | Train Acc: 97.80%
	 Val. Loss: 1.436 |  Val. Acc: 79.76%
Epoch: 98
	Train Loss: 0.054 | Train Acc: 97.73%
	 Val. Loss: 1.470 |  Val. Acc: 79.45%
Epoch: 99
	Train Loss: 0.053 | Train Acc: 97.74%
	 Val. Loss: 1.477 |  Val. Acc: 79.43%
Epoch: 100
	Train Loss: 0.055 | Train Acc: 97.71%
	 Val. Loss: 1.506 |  Val. Acc: 79.32%
valid: (0.18635458266362548, 0.9185367934405804)
test: (0.4953077044337988, 0.7911551594734192)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/govindas/venvs/expln-ai3.9/lib/python3.9/site-packages/torch/nn/modules/rnn.py:942: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  ../aten/src/ATen/native/cudnn/RNN.cpp:926.)
  result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,
</pre></div>
</div>
<img alt="../../_images/01-simulated_data_white_noise_18_3.png" src="../../_images/01-simulated_data_white_noise_18_3.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">reduce noise level and see model performance.</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">data with reduced noise level</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">nl</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">X_train_</span><span class="p">,</span> <span class="n">y_train_</span> <span class="o">=</span> <span class="n">sim_data_white_additive_noise</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">noise_level</span><span class="o">=</span><span class="n">nl</span><span class="p">)</span>
<span class="n">X_valid_</span><span class="p">,</span> <span class="n">y_valid_</span> <span class="o">=</span> <span class="n">sim_data_white_additive_noise</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">,</span> <span class="n">noise_level</span><span class="o">=</span><span class="n">nl</span><span class="p">)</span>
<span class="n">X_test_</span><span class="p">,</span> <span class="n">y_test_</span> <span class="o">=</span> <span class="n">sim_data_white_additive_noise</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">noise_level</span><span class="o">=</span><span class="n">nl</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">model</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">args</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">X_train_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">args</span><span class="o">.</span><span class="n">out_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">LABELS</span><span class="p">)</span>
<span class="n">args</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">args</span><span class="o">.</span><span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">args</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="c1"># args.num_classes = len(args.LABELS)</span>
<span class="n">args</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.5</span>

<span class="k">class</span> <span class="nc">GRU_classifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GRU_classifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span>
            <span class="n">input_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">input_dim</span><span class="p">,</span>
            <span class="n">hidden_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">dropout</span>
        <span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">out_dim</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">dropout</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

    <span class="c1"># def initHidden(self, args):</span>
        <span class="c1"># return torch.zeros(1, args.batch_size, args.num_units, device=device)</span>

    <span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">):</span>
        <span class="n">labels_pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_true</span> <span class="o">!=</span> <span class="n">args</span><span class="o">.</span><span class="n">MASK</span><span class="p">)</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">labels_pred</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">-</span> <span class="n">y_true</span><span class="p">[</span><span class="n">mask</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">correct</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">correct</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">GRU_classifier</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>

<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">MASK</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>

<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">criterion</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">X_train_</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">y_train_</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">X_valid_</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">y_valid_</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">X_test_</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">y_test_</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">permut_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">X_train_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">permut_valid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">X_valid_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">model</span><span class="p">,</span> <span class="n">best_model</span><span class="p">,</span> <span class="n">history</span><span class="p">,</span> <span class="n">best_epoch</span> <span class="o">=</span> <span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
<span class="n">plot_training_history</span><span class="p">(</span><span class="n">history</span><span class="p">,</span> <span class="n">best_epoch</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;valid: </span><span class="si">{</span><span class="n">evaluate</span><span class="p">(</span><span class="n">best_model</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">permut_valid</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">permut_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">X_test_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;test: </span><span class="si">{</span><span class="n">evaluate</span><span class="p">(</span><span class="n">best_model</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">permut_test</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/govindas/venvs/expln-ai3.9/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1
  warnings.warn(&quot;dropout option adds dropout after all but last &quot;
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 01
	Train Loss: 0.719 | Train Acc: 50.82%
	 Val. Loss: 0.693 |  Val. Acc: 50.03%
Epoch: 02
	Train Loss: 0.660 | Train Acc: 57.87%
	 Val. Loss: 0.635 |  Val. Acc: 58.16%
Epoch: 03
	Train Loss: 0.592 | Train Acc: 73.62%
	 Val. Loss: 0.559 |  Val. Acc: 86.63%
Epoch: 04
	Train Loss: 0.503 | Train Acc: 88.20%
	 Val. Loss: 0.456 |  Val. Acc: 93.58%
Epoch: 05
	Train Loss: 0.392 | Train Acc: 94.38%
	 Val. Loss: 0.341 |  Val. Acc: 94.65%
Epoch: 06
	Train Loss: 0.293 | Train Acc: 96.81%
	 Val. Loss: 0.248 |  Val. Acc: 94.71%
Epoch: 07
	Train Loss: 0.219 | Train Acc: 97.82%
	 Val. Loss: 0.188 |  Val. Acc: 94.68%
Epoch: 08
	Train Loss: 0.169 | Train Acc: 98.29%
	 Val. Loss: 0.154 |  Val. Acc: 94.63%
Epoch: 09
	Train Loss: 0.135 | Train Acc: 98.68%
	 Val. Loss: 0.133 |  Val. Acc: 94.66%
Epoch: 10
	Train Loss: 0.112 | Train Acc: 98.90%
	 Val. Loss: 0.120 |  Val. Acc: 94.72%
Epoch: 11
	Train Loss: 0.094 | Train Acc: 99.08%
	 Val. Loss: 0.111 |  Val. Acc: 94.83%
Epoch: 12
	Train Loss: 0.083 | Train Acc: 99.21%
	 Val. Loss: 0.105 |  Val. Acc: 94.91%
Epoch: 13
	Train Loss: 0.073 | Train Acc: 99.29%
	 Val. Loss: 0.100 |  Val. Acc: 95.04%
Epoch: 14
	Train Loss: 0.065 | Train Acc: 99.41%
	 Val. Loss: 0.096 |  Val. Acc: 95.14%
Epoch: 15
	Train Loss: 0.059 | Train Acc: 99.38%
	 Val. Loss: 0.092 |  Val. Acc: 95.24%
Epoch: 16
	Train Loss: 0.054 | Train Acc: 99.49%
	 Val. Loss: 0.090 |  Val. Acc: 95.40%
Epoch: 17
	Train Loss: 0.050 | Train Acc: 99.59%
	 Val. Loss: 0.087 |  Val. Acc: 95.56%
Epoch: 18
	Train Loss: 0.047 | Train Acc: 99.64%
	 Val. Loss: 0.085 |  Val. Acc: 95.70%
Epoch: 19
	Train Loss: 0.043 | Train Acc: 99.73%
	 Val. Loss: 0.083 |  Val. Acc: 95.74%
Epoch: 20
	Train Loss: 0.040 | Train Acc: 99.62%
	 Val. Loss: 0.082 |  Val. Acc: 95.80%
Epoch: 21
	Train Loss: 0.038 | Train Acc: 99.65%
	 Val. Loss: 0.081 |  Val. Acc: 95.88%
Epoch: 22
	Train Loss: 0.035 | Train Acc: 99.73%
	 Val. Loss: 0.080 |  Val. Acc: 95.94%
Epoch: 23
	Train Loss: 0.034 | Train Acc: 99.73%
	 Val. Loss: 0.079 |  Val. Acc: 95.99%
Epoch: 24
	Train Loss: 0.032 | Train Acc: 99.69%
	 Val. Loss: 0.078 |  Val. Acc: 96.05%
Epoch: 25
	Train Loss: 0.030 | Train Acc: 99.74%
	 Val. Loss: 0.077 |  Val. Acc: 96.12%
Epoch: 26
	Train Loss: 0.028 | Train Acc: 99.75%
	 Val. Loss: 0.076 |  Val. Acc: 96.18%
Epoch: 27
	Train Loss: 0.027 | Train Acc: 99.71%
	 Val. Loss: 0.075 |  Val. Acc: 96.22%
Epoch: 28
	Train Loss: 0.026 | Train Acc: 99.72%
	 Val. Loss: 0.075 |  Val. Acc: 96.24%
Epoch: 29
	Train Loss: 0.025 | Train Acc: 99.71%
	 Val. Loss: 0.075 |  Val. Acc: 96.26%
Epoch: 30
	Train Loss: 0.023 | Train Acc: 99.82%
	 Val. Loss: 0.074 |  Val. Acc: 96.29%
Epoch: 31
	Train Loss: 0.024 | Train Acc: 99.68%
	 Val. Loss: 0.074 |  Val. Acc: 96.34%
Epoch: 32
	Train Loss: 0.022 | Train Acc: 99.80%
	 Val. Loss: 0.074 |  Val. Acc: 96.35%
Epoch: 33
	Train Loss: 0.021 | Train Acc: 99.77%
	 Val. Loss: 0.074 |  Val. Acc: 96.38%
Epoch: 34
	Train Loss: 0.021 | Train Acc: 99.76%
	 Val. Loss: 0.074 |  Val. Acc: 96.38%
Epoch: 35
	Train Loss: 0.021 | Train Acc: 99.76%
	 Val. Loss: 0.073 |  Val. Acc: 96.38%
Epoch: 36
	Train Loss: 0.019 | Train Acc: 99.87%
	 Val. Loss: 0.073 |  Val. Acc: 96.41%
Epoch: 37
	Train Loss: 0.019 | Train Acc: 99.80%
	 Val. Loss: 0.073 |  Val. Acc: 96.41%
Epoch: 38
	Train Loss: 0.018 | Train Acc: 99.79%
	 Val. Loss: 0.074 |  Val. Acc: 96.42%
Epoch: 39
	Train Loss: 0.017 | Train Acc: 99.79%
	 Val. Loss: 0.074 |  Val. Acc: 96.46%
Epoch: 40
	Train Loss: 0.017 | Train Acc: 99.82%
	 Val. Loss: 0.073 |  Val. Acc: 96.48%
Epoch: 41
	Train Loss: 0.016 | Train Acc: 99.84%
	 Val. Loss: 0.073 |  Val. Acc: 96.50%
Epoch: 42
	Train Loss: 0.016 | Train Acc: 99.78%
	 Val. Loss: 0.073 |  Val. Acc: 96.55%
Epoch: 43
	Train Loss: 0.016 | Train Acc: 99.77%
	 Val. Loss: 0.073 |  Val. Acc: 96.57%
Epoch: 44
	Train Loss: 0.015 | Train Acc: 99.81%
	 Val. Loss: 0.073 |  Val. Acc: 96.61%
Epoch: 45
	Train Loss: 0.016 | Train Acc: 99.75%
	 Val. Loss: 0.073 |  Val. Acc: 96.63%
Epoch: 46
	Train Loss: 0.015 | Train Acc: 99.76%
	 Val. Loss: 0.073 |  Val. Acc: 96.62%
Epoch: 47
	Train Loss: 0.014 | Train Acc: 99.78%
	 Val. Loss: 0.073 |  Val. Acc: 96.64%
Epoch: 48
	Train Loss: 0.015 | Train Acc: 99.73%
	 Val. Loss: 0.074 |  Val. Acc: 96.65%
Epoch: 49
	Train Loss: 0.014 | Train Acc: 99.83%
	 Val. Loss: 0.073 |  Val. Acc: 96.69%
Epoch: 50
	Train Loss: 0.014 | Train Acc: 99.81%
	 Val. Loss: 0.073 |  Val. Acc: 96.69%
Epoch: 51
	Train Loss: 0.013 | Train Acc: 99.80%
	 Val. Loss: 0.073 |  Val. Acc: 96.69%
Epoch: 52
	Train Loss: 0.013 | Train Acc: 99.76%
	 Val. Loss: 0.074 |  Val. Acc: 96.69%
Epoch: 53
	Train Loss: 0.013 | Train Acc: 99.81%
	 Val. Loss: 0.074 |  Val. Acc: 96.69%
Epoch: 54
	Train Loss: 0.013 | Train Acc: 99.78%
	 Val. Loss: 0.075 |  Val. Acc: 96.69%
Epoch: 55
	Train Loss: 0.012 | Train Acc: 99.78%
	 Val. Loss: 0.074 |  Val. Acc: 96.69%
Epoch: 56
	Train Loss: 0.012 | Train Acc: 99.83%
	 Val. Loss: 0.075 |  Val. Acc: 96.70%
Epoch: 57
	Train Loss: 0.012 | Train Acc: 99.82%
	 Val. Loss: 0.075 |  Val. Acc: 96.71%
Epoch: 58
	Train Loss: 0.012 | Train Acc: 99.80%
	 Val. Loss: 0.075 |  Val. Acc: 96.73%
Epoch: 59
	Train Loss: 0.011 | Train Acc: 99.76%
	 Val. Loss: 0.075 |  Val. Acc: 96.76%
Epoch: 60
	Train Loss: 0.011 | Train Acc: 99.80%
	 Val. Loss: 0.075 |  Val. Acc: 96.79%
Epoch: 61
	Train Loss: 0.011 | Train Acc: 99.81%
	 Val. Loss: 0.075 |  Val. Acc: 96.83%
Epoch: 62
	Train Loss: 0.011 | Train Acc: 99.86%
	 Val. Loss: 0.074 |  Val. Acc: 96.83%
Epoch: 63
	Train Loss: 0.011 | Train Acc: 99.86%
	 Val. Loss: 0.075 |  Val. Acc: 96.83%
Epoch: 64
	Train Loss: 0.010 | Train Acc: 99.83%
	 Val. Loss: 0.075 |  Val. Acc: 96.83%
Epoch: 65
	Train Loss: 0.011 | Train Acc: 99.76%
	 Val. Loss: 0.075 |  Val. Acc: 96.84%
Epoch: 66
	Train Loss: 0.010 | Train Acc: 99.79%
	 Val. Loss: 0.075 |  Val. Acc: 96.86%
Epoch: 67
	Train Loss: 0.010 | Train Acc: 99.82%
	 Val. Loss: 0.076 |  Val. Acc: 96.85%
Epoch: 68
	Train Loss: 0.011 | Train Acc: 99.78%
	 Val. Loss: 0.076 |  Val. Acc: 96.86%
Epoch: 69
	Train Loss: 0.009 | Train Acc: 99.81%
	 Val. Loss: 0.076 |  Val. Acc: 96.87%
Epoch: 70
	Train Loss: 0.009 | Train Acc: 99.88%
	 Val. Loss: 0.076 |  Val. Acc: 96.87%
Epoch: 71
	Train Loss: 0.009 | Train Acc: 99.85%
	 Val. Loss: 0.076 |  Val. Acc: 96.88%
Epoch: 72
	Train Loss: 0.010 | Train Acc: 99.80%
	 Val. Loss: 0.077 |  Val. Acc: 96.89%
Epoch: 73
	Train Loss: 0.009 | Train Acc: 99.80%
	 Val. Loss: 0.077 |  Val. Acc: 96.91%
Epoch: 74
	Train Loss: 0.010 | Train Acc: 99.78%
	 Val. Loss: 0.077 |  Val. Acc: 96.92%
Epoch: 75
	Train Loss: 0.009 | Train Acc: 99.88%
	 Val. Loss: 0.077 |  Val. Acc: 96.92%
Epoch: 76
	Train Loss: 0.009 | Train Acc: 99.82%
	 Val. Loss: 0.077 |  Val. Acc: 96.92%
Epoch: 77
	Train Loss: 0.008 | Train Acc: 99.82%
	 Val. Loss: 0.077 |  Val. Acc: 96.93%
Epoch: 78
	Train Loss: 0.008 | Train Acc: 99.87%
	 Val. Loss: 0.077 |  Val. Acc: 96.94%
Epoch: 79
	Train Loss: 0.008 | Train Acc: 99.81%
	 Val. Loss: 0.077 |  Val. Acc: 96.95%
Epoch: 80
	Train Loss: 0.008 | Train Acc: 99.84%
	 Val. Loss: 0.077 |  Val. Acc: 96.97%
Epoch: 81
	Train Loss: 0.009 | Train Acc: 99.75%
	 Val. Loss: 0.078 |  Val. Acc: 96.97%
Epoch: 82
	Train Loss: 0.009 | Train Acc: 99.78%
	 Val. Loss: 0.078 |  Val. Acc: 96.96%
Epoch: 83
	Train Loss: 0.009 | Train Acc: 99.76%
	 Val. Loss: 0.078 |  Val. Acc: 96.97%
Epoch: 84
	Train Loss: 0.008 | Train Acc: 99.82%
	 Val. Loss: 0.078 |  Val. Acc: 96.98%
Epoch: 85
	Train Loss: 0.009 | Train Acc: 99.77%
	 Val. Loss: 0.078 |  Val. Acc: 96.99%
Epoch: 86
	Train Loss: 0.008 | Train Acc: 99.82%
	 Val. Loss: 0.079 |  Val. Acc: 96.99%
Epoch: 87
	Train Loss: 0.008 | Train Acc: 99.76%
	 Val. Loss: 0.079 |  Val. Acc: 96.97%
Epoch: 88
	Train Loss: 0.008 | Train Acc: 99.79%
	 Val. Loss: 0.079 |  Val. Acc: 96.99%
Epoch: 89
	Train Loss: 0.008 | Train Acc: 99.82%
	 Val. Loss: 0.079 |  Val. Acc: 96.97%
Epoch: 90
	Train Loss: 0.008 | Train Acc: 99.77%
	 Val. Loss: 0.079 |  Val. Acc: 96.97%
Epoch: 91
	Train Loss: 0.008 | Train Acc: 99.79%
	 Val. Loss: 0.080 |  Val. Acc: 96.97%
Epoch: 92
	Train Loss: 0.008 | Train Acc: 99.80%
	 Val. Loss: 0.080 |  Val. Acc: 96.97%
Epoch: 93
	Train Loss: 0.007 | Train Acc: 99.84%
	 Val. Loss: 0.080 |  Val. Acc: 96.97%
Epoch: 94
	Train Loss: 0.007 | Train Acc: 99.82%
	 Val. Loss: 0.080 |  Val. Acc: 96.98%
Epoch: 95
	Train Loss: 0.008 | Train Acc: 99.78%
	 Val. Loss: 0.081 |  Val. Acc: 96.96%
Epoch: 96
	Train Loss: 0.007 | Train Acc: 99.81%
	 Val. Loss: 0.082 |  Val. Acc: 96.96%
Epoch: 97
	Train Loss: 0.008 | Train Acc: 99.79%
	 Val. Loss: 0.081 |  Val. Acc: 96.99%
Epoch: 98
	Train Loss: 0.007 | Train Acc: 99.79%
	 Val. Loss: 0.081 |  Val. Acc: 97.00%
Epoch: 99
	Train Loss: 0.007 | Train Acc: 99.81%
	 Val. Loss: 0.082 |  Val. Acc: 97.00%
Epoch: 100
	Train Loss: 0.007 | Train Acc: 99.85%
	 Val. Loss: 0.082 |  Val. Acc: 97.01%
valid: (0.07273906609043479, 0.9660794362425804)
test: (0.25409327540546656, 0.915108859539032)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/govindas/venvs/expln-ai3.9/lib/python3.9/site-packages/torch/nn/modules/rnn.py:942: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  ../aten/src/ATen/native/cudnn/RNN.cpp:926.)
  result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,
</pre></div>
</div>
<img alt="../../_images/01-simulated_data_white_noise_19_3.png" src="../../_images/01-simulated_data_white_noise_19_3.png" />
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./nb/jun22"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="01-max_data_samples.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">May 30, 2022: Data samples and model</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="01-simulated_data_wss_noise.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">June 6-8, 2022: simulated data: wss noise</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Govinda Surampudi<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>